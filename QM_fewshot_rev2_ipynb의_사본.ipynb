{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongYun1/CodeLab/blob/main/QM_fewshot_rev2_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lQwaOnAnyEJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 60000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC8KJ4GWn1SH",
        "outputId": "04d96033-4ccb-4ad6-dbb0-bb696bc72cf3"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momw-1.4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py:133\u001b[0m\n\u001b[0;32m    125\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mPopen \u001b[38;5;241m=\u001b[39m _fake_Popen\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# TOP-LEVEL MODULES\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Import top-level functionality into top-level namespace\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollocations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator, memoize\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatstruct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\collocations.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_itertools\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# these two unused imports are referenced in collocations.doctest\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     BigramAssocMeasures,\n\u001b[0;32m     38\u001b[0m     ContingencyMeasures,\n\u001b[0;32m     39\u001b[0m     QuadgramAssocMeasures,\n\u001b[0;32m     40\u001b[0m     TrigramAssocMeasures,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspearman\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ranks_from_scores, spearman_correlation\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\metrics\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magreement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotationTask\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m align\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massociation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     BigramAssocMeasures,\n\u001b[0;32m     20\u001b[0m     ContingencyMeasures,\n\u001b[0;32m     21\u001b[0m     NgramAssocMeasures,\n\u001b[0;32m     22\u001b[0m     QuadgramAssocMeasures,\n\u001b[0;32m     23\u001b[0m     TrigramAssocMeasures,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfusionmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrix\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     binary_distance,\n\u001b[0;32m     28\u001b[0m     custom_distance,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     presence,\n\u001b[0;32m     36\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\metrics\\association.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m _SMALL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-20\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fisher_exact\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfisher_exact\u001b[39m(\u001b[38;5;241m*\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs):\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[0;32m     49\u001b[0m                                    siegelslopes)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:23\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb, entr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# for root finding for continuous distribution ppf, and maximum likelihood\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# estimation\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integrate\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\__init__.py:189\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 189\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\__init__.py:422\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nnls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nnls\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basinhopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m basinhopping\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linprog, linprog_verbose_callback\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lsap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_sum_assignment\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_differentialevolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m differential_evolution\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linprog.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeResult, OptimizeWarning\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_highs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_highs\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_ip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_ip\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linprog_simplex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _linprog_simplex\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linprog_highs.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeWarning, OptimizeResult\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_highs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_highs_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _highs_wrapper\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_highs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_highs_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     CONST_INF,\n\u001b[0;32m     23\u001b[0m     MESSAGE_LEVEL_NONE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     HIGHS_SIMPLEX_EDGE_WEIGHT_STRATEGY_STEEPEST_EDGE,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csc_matrix, vstack, issparse\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ClPZyvIqtL",
        "outputId": "55f9b47c-88f3-4df4-8e4a-d53aa96af377"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>호선</th>\n",
              "      <th>H.C/Close</th>\n",
              "      <th>진행상태</th>\n",
              "      <th>부서진행상태</th>\n",
              "      <th>QM확인</th>\n",
              "      <th>SCAS_CNO</th>\n",
              "      <th>코멘트번호</th>\n",
              "      <th>ORI_CMT_NO</th>\n",
              "      <th>제목</th>\n",
              "      <th>문제내용</th>\n",
              "      <th>문제내용(ICON)</th>\n",
              "      <th>문제내용(번역)</th>\n",
              "      <th>문제내용(번역 ICON)</th>\n",
              "      <th>파일</th>\n",
              "      <th>진행상태2</th>\n",
              "      <th>처리부서</th>\n",
              "      <th>처리과</th>\n",
              "      <th>처리부서(후처리)</th>\n",
              "      <th>담당자</th>\n",
              "      <th>담당자 선택</th>\n",
              "      <th>확정자</th>\n",
              "      <th>이엔티/부서</th>\n",
              "      <th>이엔티/과</th>\n",
              "      <th>REPLY 상태</th>\n",
              "      <th>회신내용</th>\n",
              "      <th>Maker 조치예정일</th>\n",
              "      <th>Maker업체명</th>\n",
              "      <th>Maker작업자</th>\n",
              "      <th>Maker연락처</th>\n",
              "      <th>Maker eMail</th>\n",
              "      <th>Maker 선택</th>\n",
              "      <th>완료예정일</th>\n",
              "      <th>원인부서</th>\n",
              "      <th>원인과</th>\n",
              "      <th>구역</th>\n",
              "      <th>BLOCK</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>결함코드</th>\n",
              "      <th>원인</th>\n",
              "      <th>발행자이름</th>\n",
              "      <th>검사원성명</th>\n",
              "      <th>후속호선 반영여부</th>\n",
              "      <th>개정도유무</th>\n",
              "      <th>HHI COMPLETED일자</th>\n",
              "      <th>종료일자</th>\n",
              "      <th>종료자1</th>\n",
              "      <th>S/T(ref)</th>\n",
              "      <th>S/T</th>\n",
              "      <th>지연일</th>\n",
              "      <th>접수지연일</th>\n",
              "      <th>최근회신일</th>\n",
              "      <th>발행일</th>\n",
              "      <th>등록일</th>\n",
              "      <th>접수일</th>\n",
              "      <th>G/T(ref)</th>\n",
              "      <th>G/T</th>\n",
              "      <th>AS이관일</th>\n",
              "      <th>QM확인완료일</th>\n",
              "      <th>최초회신일</th>\n",
              "      <th>회신일</th>\n",
              "      <th>회신건수</th>\n",
              "      <th>3일이내 회신건수</th>\n",
              "      <th>처리일</th>\n",
              "      <th>처리건수</th>\n",
              "      <th>3일이내 처리건수</th>\n",
              "      <th>최종변경자성명</th>\n",
              "      <th>소요공수</th>\n",
              "      <th>실패비용</th>\n",
              "      <th>중요도</th>\n",
              "      <th>지연보류 해제</th>\n",
              "      <th>지연보류 해제일</th>\n",
              "      <th>검사제한여부</th>\n",
              "      <th>ORDER NO.</th>\n",
              "      <th>DESC.</th>\n",
              "      <th>주관부서</th>\n",
              "      <th>검사결과</th>\n",
              "      <th>처리부서 미조치</th>\n",
              "      <th>LQC 소속</th>\n",
              "      <th>LQC 이름</th>\n",
              "      <th>Maker A/S</th>\n",
              "      <th>자재입고</th>\n",
              "      <th>S/T3</th>\n",
              "      <th>G/T4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3040</td>\n",
              "      <td>Indeterminate</td>\n",
              "      <td>CLOSED</td>\n",
              "      <td>QM확인완료</td>\n",
              "      <td>Unchecked</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C-3040-B-AB-00001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bunker specification using the sea trial to be submitted to the class.</td>\n",
              "      <td>Bunker specification using the sea trial to be submitted to the class.</td>\n",
              "      <td>Bunker specification using the sea trial to be submitted to the class.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CLOSED</td>\n",
              "      <td>시운전부</td>\n",
              "      <td>기관1과(C853-000)</td>\n",
              "      <td>Unchecked</td>\n",
              "      <td>이번하</td>\n",
              "      <td>Indeterminate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>QM Confirmed(QM확인완료)</td>\n",
              "      <td>금일 선주 사인 받았습니다.  종결처리 부탁드립니다.\\n(첨부 사진 전송 완료)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unchecked</td>\n",
              "      <td>2019-03-22</td>\n",
              "      <td>시운전부(C850)</td>\n",
              "      <td>기관1과(C853-000)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>NaN</td>\n",
              "      <td>JEE</td>\n",
              "      <td>JEE:작업예정(자재미입고, 싯점대기)</td>\n",
              "      <td>박정준(J.J. PARK)</td>\n",
              "      <td>김태진</td>\n",
              "      <td>Unchecked</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-03-13</td>\n",
              "      <td>김태진</td>\n",
              "      <td>2019-03-04</td>\n",
              "      <td>2019-02-07</td>\n",
              "      <td>1,094</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-03-13</td>\n",
              "      <td>2019-03-11</td>\n",
              "      <td>2019-03-11</td>\n",
              "      <td>2019-03-12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-03-13</td>\n",
              "      <td>2019-03-12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>김태진</td>\n",
              "      <td>NaN</td>\n",
              "      <td>171,456.0</td>\n",
              "      <td>중</td>\n",
              "      <td>Unchecked</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Indeterminate</td>\n",
              "      <td>Indeterminate</td>\n",
              "      <td>Indeterminate</td>\n",
              "      <td>Indeterminate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     호선      H.C/Close    진행상태  부서진행상태       QM확인 SCAS_CNO              코멘트번호  \\\n",
              "0  3040  Indeterminate  CLOSED  QM확인완료  Unchecked      NaN  C-3040-B-AB-00001   \n",
              "\n",
              "  ORI_CMT_NO  \\\n",
              "0        NaN   \n",
              "\n",
              "                                                                       제목  \\\n",
              "0  Bunker specification using the sea trial to be submitted to the class.   \n",
              "\n",
              "                                                                     문제내용  \\\n",
              "0  Bunker specification using the sea trial to be submitted to the class.   \n",
              "\n",
              "                                                               문제내용(ICON)  \\\n",
              "0  Bunker specification using the sea trial to be submitted to the class.   \n",
              "\n",
              "  문제내용(번역) 문제내용(번역 ICON)   파일   진행상태2  처리부서             처리과  처리부서(후처리)  담당자  \\\n",
              "0      NaN           NaN  NaN  CLOSED  시운전부  기관1과(C853-000)  Unchecked  이번하   \n",
              "\n",
              "          담당자 선택  확정자  이엔티/부서  이엔티/과              REPLY 상태  \\\n",
              "0  Indeterminate  NaN     NaN    NaN  QM Confirmed(QM확인완료)   \n",
              "\n",
              "                                           회신내용  Maker 조치예정일  Maker업체명  \\\n",
              "0  금일 선주 사인 받았습니다.  종결처리 부탁드립니다.\\n(첨부 사진 전송 완료)          NaN       NaN   \n",
              "\n",
              "   Maker작업자  Maker연락처  Maker eMail   Maker 선택       완료예정일        원인부서  \\\n",
              "0       NaN       NaN          NaN  Unchecked  2019-03-22  시운전부(C850)   \n",
              "\n",
              "              원인과   구역 BLOCK LOCATION 결함코드                     원인  \\\n",
              "0  기관1과(C853-000)  NaN  해당없음      NaN  JEE  JEE:작업예정(자재미입고, 싯점대기)   \n",
              "\n",
              "            발행자이름 검사원성명  후속호선 반영여부 개정도유무 HHI COMPLETED일자        종료일자 종료자1  \\\n",
              "0  박정준(J.J. PARK)   김태진  Unchecked   NaN             NaN  2019-03-13  김태진   \n",
              "\n",
              "     S/T(ref)         S/T    지연일  접수지연일       최근회신일         발행일         등록일  \\\n",
              "0  2019-03-04  2019-02-07  1,094    1.0  2019-03-13  2019-03-11  2019-03-11   \n",
              "\n",
              "          접수일 G/T(ref)  G/T AS이관일     QM확인완료일       최초회신일  회신일  회신건수  \\\n",
              "0  2019-03-12      NaN  NaN   NaN  2019-03-13  2019-03-12  NaN     1   \n",
              "\n",
              "   3일이내 회신건수  처리일  처리건수  3일이내 처리건수 최종변경자성명  소요공수       실패비용 중요도    지연보류 해제  \\\n",
              "0          1  2.0     1          1     김태진   NaN  171,456.0   중  Unchecked   \n",
              "\n",
              "  지연보류 해제일  검사제한여부 ORDER NO. DESC.  주관부서 검사결과 처리부서 미조치  LQC 소속  LQC 이름  \\\n",
              "0      NaN     NaN       NaN   NaN   NaN  NaN        N     NaN     NaN   \n",
              "\n",
              "       Maker A/S           자재입고           S/T3           G/T4  \n",
              "0  Indeterminate  Indeterminate  Indeterminate  Indeterminate  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(47741, 83)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel(\"dataset02.xlsx\")\n",
        "df.head(1)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wOGa4YDn086",
        "outputId": "852e9999-31c5-4364-e4de-16def97751b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(47741, 10)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[[\"호선\", \"코멘트번호\", \"제목\", \"문제내용\", \"처리부서\", \"처리과\", \"회신내용\", \"구역\", \"LOCATION\", \"BLOCK\"]]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsoCk_ILn06O",
        "outputId": "ac4ccbdd-8367-4e50-eccd-2decdfdb5329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46145, 10)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_drop = ['이관', \"재지정\", \"재 지정\"]\n",
        "for drop_word in text_to_drop:\n",
        "    df = df[~df['회신내용'].str.contains(drop_word, regex=True, na=False)]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMCRofV3n03Y",
        "outputId": "3d6af957-a02f-45b7-ebe7-01ea33aad5e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "직능\n",
              "일반     15135\n",
              "기장      7894\n",
              "전장      7537\n",
              "선장      3889\n",
              "선실      3847\n",
              "공사      2219\n",
              "도장      1568\n",
              "엔진      1564\n",
              "기계       937\n",
              "기관       636\n",
              "시운전      500\n",
              "건조       302\n",
              "발판        70\n",
              "보냉        47\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def contains_word(main_string, target_word):\n",
        "    return target_word in main_string\n",
        "\n",
        "기준직능 = [\"선장\", \"기장\",\"전장\", \"선실\", \"엔진\", \"기관\", \"기계\", \"도장\", \"건조\", \"시운전\",\"발판\", \"보냉\", \"공사\"]\n",
        "         #\"의장\", \"설계\",\"선행\",\n",
        "\n",
        "def 직능구하기(string):\n",
        "    global 기준직능\n",
        "    result = \"일반\"\n",
        "    for 직능 in 기준직능:\n",
        "        if contains_word(str(string), 직능):\n",
        "            result = 직능\n",
        "        else:\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "df[\"직능\"] = df[\"처리과\"].apply(직능구하기)\n",
        "\n",
        "df[\"직능\"].fillna(\"일반\", inplace=True)\n",
        "df[\"직능\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHziol56oIfl"
      },
      "outputs": [],
      "source": [
        "df['직능'] = df['직능'].str.replace(\"보냉\", '도장', regex=True)\n",
        "df['직능'] = df['직능'].str.replace(\"발판\", '도장', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4WFQETGoIdf",
        "outputId": "d258041b-f6e5-483a-b11f-513235e1d7b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46145, 11)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(31010, 11)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape\n",
        "df = df[df[\"직능\"]!=\"일반\"]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSiSOG-roIa6",
        "outputId": "fe97b6e2-9e07-4a0a-b143-d991677adcaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22668, 11)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop_duplicates(subset='코멘트번호', keep='first')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK2kPmHotRed",
        "outputId": "561972d7-43ac-4090-da9d-095772fd4a9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 14043494939643941341\n",
              " xla_global_id: -1]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGayzKokoIYd"
      },
      "outputs": [],
      "source": [
        "import functools # not required, but helps in production\n",
        "def unpack_df_columns(func):\n",
        "\n",
        "    @functools.wraps(func)\n",
        "    def _unpack_df_columns(*args, **kwargs):\n",
        "\n",
        "        series = args[0]\n",
        "        return func(*series.values)\n",
        "\n",
        "    return _unpack_df_columns\n",
        "\n",
        "def jaccard_simil(a, b):\n",
        "    intersection_cardinality = len(set.intersection(*[set(str(a)), set(str(b))]))\n",
        "    union_cardinality = len(set.union(*[set(str(a)), set(str(b))]))\n",
        "    similar = intersection_cardinality / float(union_cardinality)\n",
        "    return similar\n",
        "\n",
        "@unpack_df_columns\n",
        "def 문장병합(제목, 문제내용):\n",
        "    '''\n",
        "    자카드유사도가 일정 수준 이상이면 제목과 문제내용중 길이가 긴 내용만 살리기\n",
        "    '''\n",
        "    자카드유사도 = jaccard_simil(제목, 문제내용)\n",
        "    thresh = 0.9  # 유사도 커트라인\n",
        "\n",
        "    if 자카드유사도 > thresh:\n",
        "        if len(str(제목)) > len(str(문제내용)):\n",
        "            return 문제내용\n",
        "        else:\n",
        "            return 제목\n",
        "    else:\n",
        "        return f\"{제목} {문제내용}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC3oaPO5oIV8"
      },
      "outputs": [],
      "source": [
        "df['comment'] = df[['제목',\"문제내용\"]].apply(문장병합, axis=1)\n",
        "df.dropna(subset=[\"comment\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RM-gvFrn0xJ"
      },
      "outputs": [],
      "source": [
        "korean_pattern = '[\\u3131-\\u3163\\uac00-\\ud7a3]+'\n",
        "df = df[~df['comment'].str.contains(korean_pattern, regex=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0IQuw2BoSmf",
        "outputId": "b98ccad0-7d1c-4d70-def6-0722c96fee15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bunker specification using the sea trial to be submitted to the class.</td>\n",
              "      <td>기관</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. The following operational procedures are to be provided.\\n'1)  Fuel-change over</td>\n",
              "      <td>기장</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                 text  \\\n",
              "0              Bunker specification using the sea trial to be submitted to the class.   \n",
              "1  1. The following operational procedures are to be provided.\\n'1)  Fuel-change over   \n",
              "\n",
              "  label  \n",
              "0    기관  \n",
              "1    기장  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 =df[[\"comment\", \"직능\"]]\n",
        "df1.columns = [\"text\", \"label\"]\n",
        "df1 = df1.reset_index(drop=True)\n",
        "df1.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAcA0OrykX0W",
        "outputId": "124b21ec-8204-4133-82b1-b9abb6a8074d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        0\n",
              "1        1\n",
              "2        0\n",
              "3        1\n",
              "4        2\n",
              "        ..\n",
              "18919    3\n",
              "18920    4\n",
              "18921    6\n",
              "18922    3\n",
              "18923    2\n",
              "Name: label, Length: 18924, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_labels = {'기관':0, '기장':1, '선장':2, '전장':3, '선실':4, '건조':5, '시운전':6, '도장':7, '엔진':8, '기계':9, '공사':10}\n",
        "df1[\"label\"] = df1[\"label\"].replace(to_replace=new_labels)\n",
        "df1[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWQaL4SGkXxk",
        "outputId": "b0fcd07c-4cea-4984-80e3-016c6334b597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['기관', '기장', '선장', '전장', '선실', '건조', '시운전', '도장', '엔진', '기계', '공사']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = new_labels.keys()\n",
        "classes = list(classes)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy0VTNM2kXvB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk_Yc3SAkXsg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJb1X6IVoSj_",
        "outputId": "70c9c80f-cc41-4302-fa8e-ce3b19d89a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18924, 2)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "((13246, 2), (5678, 2))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df1.shape\n",
        "train, val= train_test_split(df1, test_size=0.3, random_state=123, shuffle=True, stratify=df1[\"label\"])\n",
        "train.shape, val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Y2g3QooSg3",
        "outputId": "8debd3bc-fd71-4c29-e725-ad36e60448a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3974, 2), (1704, 2))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val, test= train_test_split(val, test_size=0.3, random_state=123, shuffle=True, stratify=val[\"label\"])\n",
        "\n",
        "val.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQW6H1dZocW1",
        "outputId": "affc0858-3632-4b5e-d760-9958835ff4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers accelerate setfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcj21kPCocUf"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFuImU1CocRu"
      },
      "outputs": [],
      "source": [
        "train1 = Dataset.from_pandas(train)\n",
        "val1 = Dataset.from_pandas(val)\n",
        "test1  = Dataset.from_pandas(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V51M76XRocPY"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetDict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO0SMTRxocMy"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"] = train1\n",
        "dataset[\"validation\"] = val1\n",
        "dataset[\"test\"] = test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZN97tchocKd"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "val_dataset = dataset[\"validation\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At30fbS1oiiv",
        "outputId": "a0593c53-290b-46bb-c272-11e3e20d9777"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', '__index_level_0__'],\n",
              "    num_rows: 13246\n",
              "})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aihKR0d5U1CP",
        "outputId": "b1af4b84-0649-4917-b0d3-6b7954f85f64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', '__index_level_0__'],\n",
              "    num_rows: 3974\n",
              "})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOMIL51xU-aF",
        "outputId": "c9f724d9-c7ff-48cb-e026-18d3ffc8dff5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', '__index_level_0__'],\n",
              "    num_rows: 1704\n",
              "})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYEjFngJefFd"
      },
      "outputs": [],
      "source": [
        "def get_train_dataset(dataset, N):\n",
        "    ids = []\n",
        "    label2count = {}\n",
        "    train_dataset = dataset['train'].shuffle(seed=41)\n",
        "    for id, example in enumerate(train_dataset):\n",
        "        if example['label'] not in label2count:\n",
        "            label2count[example['label']]=1\n",
        "        elif label2count[example['label']]>=N:\n",
        "            continue\n",
        "        else:\n",
        "            label2count[example['label']]+=1\n",
        "        ids.append(id)\n",
        "    return train_dataset.select(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoI-tNJNefAU",
        "outputId": "c5a7ae42-e83f-4239-c8de-786a1f447152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', '__index_level_0__'],\n",
              "    num_rows: 55\n",
              "})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 5\n",
        "train_dataset = get_train_dataset(dataset, N)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWz1GnNsoidw"
      },
      "outputs": [],
      "source": [
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9Llf7aSoiba",
        "outputId": "cab18d7f-6c7e-41ca-d3e4-1843e0f92dcd",
        "colab": {
          "referenced_widgets": [
            "de475560376f4275a315aa333223c9f3",
            "5730b62014a64132bb67b0338ab2e911",
            "0540ca1977e24765be94adc97fcd9d0f",
            "c834d27aee824428bd6bf330bdde07be",
            "66011f021c5040858091d94c244c8428",
            "a6e23a45823c424f8b487befadcc29b6",
            "0c05f799c00445c3b81d0393c42c5fc8"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\irene\\anaconda3\\Lib\\site-packages\\ipywidgets\\widgets\\widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
            "  self.comm = Comm(**args)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de475560376f4275a315aa333223c9f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5730b62014a64132bb67b0338ab2e911",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0540ca1977e24765be94adc97fcd9d0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c834d27aee824428bd6bf330bdde07be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading README.md:   0%|          | 0.00/90.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66011f021c5040858091d94c244c8428",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e23a45823c424f8b487befadcc29b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c05f799c00445c3b81d0393c42c5fc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSetFitModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBAAI/bge-base-en-v1.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m args1 \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      5\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# load_best_model_at_end=True,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m trainer1 \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     13\u001b[0m     args\u001b[38;5;241m=\u001b[39margs1,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     column_mapping\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     18\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\hub_mixin.py:159\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    157\u001b[0m     model_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config})\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\setfit\\modeling.py:701\u001b[0m, in \u001b[0;36mSetFitModel._from_pretrained\u001b[1;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, multi_target_strategy, use_differentiable_head, device, **model_kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pretrained\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetFitModel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 701\u001b[0m     model_body \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m     device \u001b[38;5;241m=\u001b[39m model_body\u001b[38;5;241m.\u001b[39m_target_device\n\u001b[0;32m    703\u001b[0m     model_body\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# put `model_body` on the target device\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     83\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;66;03m# Download from hub with caching\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mignore_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflax_model.msgpack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrust_model.ot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(model_path)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\util.py:491\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(huggingface_hub\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.8.1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# huggingface_hub v0.8.1 introduces a new cache layout. We sill use a manual layout\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;66;03m# And need to pass legacy_cache_layout=True to avoid that a warning will be printed\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     cached_download_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegacy_cache_layout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mcached_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_download_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.lock\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    494\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.lock\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:808\u001b[0m, in \u001b[0;36mcached_download\u001b[1;34m(url, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[0;32m    806\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 808\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, cache_path)\n\u001b[0;32m    818\u001b[0m _chmod_and_replace(temp_file\u001b[38;5;241m.\u001b[39mname, cache_path)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:551\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    541\u001b[0m     displayed_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(…)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[0;32m    544\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    545\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(logger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel() \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mNOTSET),\n\u001b[0;32m    550\u001b[0m )\n\u001b[1;32m--> 551\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = SetFitModel.from_pretrained(\"BAAI/bge-base-en-v1.5\")\n",
        "\n",
        "args1 = TrainingArguments(\n",
        "    batch_size=32,\n",
        "    num_epochs=1,\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    # save_strategy=\"epoch\",\n",
        "    # load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer1 = Trainer(\n",
        "    model=model,\n",
        "    args=args1,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    metric=\"accuracy\",\n",
        "    column_mapping={\"text\": \"text\", \"label\": \"label\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og3T4OF0oiY2"
      },
      "outputs": [],
      "source": [
        "trainer1.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oYyDjaSoiWs"
      },
      "outputs": [],
      "source": [
        "metrics = trainer1.evaluate()\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQea579zoiT_"
      },
      "outputs": [],
      "source": [
        "# trainer1.model._save_pretrained(save_directory=\"./model/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZREOd_NHocHx"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_dataset['text'])\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3CylQjgocFQ"
      },
      "outputs": [],
      "source": [
        "# print(classification_report(test_dataset['label'], preds, target_names=classes, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37wzMlCpXUyo"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_dataset['label'], preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlxHRn-2XdzA",
        "outputId": "def0d4ec-ad8d-4301-999d-5ee10866017a",
        "colab": {
          "referenced_widgets": [
            "c1ca10d7f0914b8bacfe461e8a32137b",
            "4a885ed5f91f41c58799432e829ef4eb",
            "c1b59dc4575b494499b33ce62eead908",
            "bfdb9aa94d0945d7a887a1b5a39af248",
            "85d88d9a6a9546548c484a27c793a05c",
            "99634a45daab4df591904e0d8f22c95f",
            "e572dc9b9d0a4f5eaa8098680b047dc3"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ca10d7f0914b8bacfe461e8a32137b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a885ed5f91f41c58799432e829ef4eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1b59dc4575b494499b33ce62eead908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfdb9aa94d0945d7a887a1b5a39af248",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d88d9a6a9546548c484a27c793a05c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99634a45daab4df591904e0d8f22c95f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e572dc9b9d0a4f5eaa8098680b047dc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): StableDropout()\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = 'knowledgator/comprehend_it-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeK7a4JZXdwf"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "import random\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhAYUXpPXduD",
        "outputId": "c33cb6d7-4d27-4946-b445-55a75ab2d5ba",
        "colab": {
          "referenced_widgets": [
            "e8338802534240448a128938393b356d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8338802534240448a128938393b356d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
              "Args:\n",
              "    predictions (`list` of `int`): Predicted labels.\n",
              "    references (`list` of `int`): Ground truth labels.\n",
              "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
              "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
              "\n",
              "Returns:\n",
              "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
              "\n",
              "Examples:\n",
              "\n",
              "    Example 1-A simple example\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.5}\n",
              "\n",
              "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
              "        >>> print(results)\n",
              "        {'accuracy': 3.0}\n",
              "\n",
              "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
              "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
              "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
              "        >>> print(results)\n",
              "        {'accuracy': 0.8778625954198473}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35p3Or7mXdrI"
      },
      "outputs": [],
      "source": [
        "# 샘플 데이터를 10개씩 증강.. (원래 48개인데.. 10문장씩 복사 증강하여 총 데이터가 480개가 됨)\n",
        "\n",
        "def transform_dataset(dataset, classes, template = '{}'):\n",
        "   new_dataset = {'sources':[], 'targets': [], 'labels': []}\n",
        "\n",
        "   texts = dataset['text']\n",
        "   print(f\"texts 앞에 두개: {texts}\")\n",
        "   labels = dataset['label']\n",
        "   print(f\"labels 앞에 두개: {labels}\")\n",
        "\n",
        "   label2count = {}\n",
        "   for label in labels:\n",
        "       if label not in label2count:\n",
        "           label2count[label]=1\n",
        "       else:\n",
        "           label2count[label]+=1\n",
        "   print(f\"label2count: {label2count}\")\n",
        "\n",
        "   count = len(labels)\n",
        "   print(f\"count: {count}\")\n",
        "\n",
        "   label2prob = {label:lc/count for label, lc in label2count.items()}\n",
        "   print(f\"label2prob: {label2prob}\")\n",
        "\n",
        "   unique_labels = list(label2prob)\n",
        "   print(f\"unique_labels: {unique_labels}\")\n",
        "\n",
        "   probs = list(label2prob.values())\n",
        "   print(f\"probs: {probs}\")\n",
        "\n",
        "   ids = list(range(len(labels)))\n",
        "   print(f\"ids: {ids}\")\n",
        "\n",
        "   print(f\"classes: {classes}\")\n",
        "\n",
        "   for text, label_id in zip(texts, labels):\n",
        "       label = classes[label_id]\n",
        "       for i in range(len(classes)-1):\n",
        "           new_dataset['sources'].append(text)\n",
        "           new_dataset['targets'].append(template.format(label))\n",
        "           new_dataset['labels'].append(1.)\n",
        "\n",
        "       print(f\"new_dataset1: {new_dataset}\")\n",
        "\n",
        "       for i in range(len(classes)-1):\n",
        "           neg_class_ = label\n",
        "           while neg_class_==label:\n",
        "               # neg_class_ = random.sample(classes, k=1)[0]\n",
        "               neg_lbl = np.random.choice(unique_labels, p=probs)\n",
        "               neg_class_ = classes[neg_lbl]\n",
        "\n",
        "           new_dataset['sources'].append(text)\n",
        "           new_dataset['targets'].append(template.format(neg_class_))\n",
        "           new_dataset['labels'].append(-1.)\n",
        "       print(f\"new_dataset2: {new_dataset}\")\n",
        "\n",
        "   result = Dataset.from_dict(new_dataset)\n",
        "   print(f\"result : {result}\")\n",
        "   return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZODwbG1NXqa4"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "   predictions, labels = eval_pred\n",
        "\n",
        "   predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "   return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3rdaNFaXqYa"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_label(example):\n",
        "   hypothesis = example['targets']\n",
        "\n",
        "   seq = example[\"sources\"]+hypothesis\n",
        "\n",
        "   tokenized_input = tokenizer(seq, truncation=True, max_length=512,\n",
        "                                                    padding=\"max_length\")\n",
        "\n",
        "   label = example['labels']\n",
        "   if label==1.0:\n",
        "       label = torch.tensor(1)\n",
        "   elif label==0.0:\n",
        "       label = torch.tensor(2)\n",
        "   else:\n",
        "       label = torch.tensor(0)\n",
        "   tokenized_input['label'] = label\n",
        "   return tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hysrabesXqI9",
        "outputId": "2bc9fd24-4ead-4052-a833-32cadcf3976d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataCollatorWithPadding(tokenizer=DebertaV2TokenizerFast(name_or_path='knowledgator/comprehend_it-base', vocab_size=128000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qohnp8HaXurs",
        "outputId": "4ecc5719-def9-4b88-ee38-504555ca8f9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = transform_dataset(train_dataset, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59p-64JxlZG3",
        "outputId": "fb1ee508-6d3e-41e2-e981-abd318a83778",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_and_align_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z77R7TldXupN",
        "outputId": "693e6064-820d-44b6-83fd-c47d6230dbda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sources', 'targets', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
              "        num_rows: 990\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sources', 'targets', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
              "        num_rows: 110\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H85wwx1MXumg"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "   output_dir='comprehendo',\n",
        "   learning_rate=3e-5,\n",
        "   per_device_train_batch_size=8,\n",
        "   per_device_eval_batch_size=8,\n",
        "   num_train_epochs=3,\n",
        "   weight_decay=0.01,\n",
        "   evaluation_strategy=\"epoch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As7cJs9LXuj8"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_dataset[\"train\"],\n",
        "   eval_dataset=tokenized_dataset['test'],\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGzC-wOzlj5Y",
        "outputId": "dfbe9951-5c5b-4e7b-d472-42da04fffc7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [372/372 02:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.227876</td>\n",
              "      <td>0.918182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.094219</td>\n",
              "      <td>0.963636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.048557</td>\n",
              "      <td>0.972727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=372, training_loss=0.26625844483734457, metrics={'train_runtime': 166.8186, 'train_samples_per_second': 17.804, 'train_steps_per_second': 2.23, 'total_flos': 928807021209600.0, 'train_loss': 0.26625844483734457, 'epoch': 3.0})"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC35hzDYllj8"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('comprehender')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gm57EKElpfu"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                     model='comprehender',tokenizer=tokenizer, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Fb1awLlpda",
        "outputId": "1324cb56-1dec-4ca0-f44d-0a54c7653eac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████| 1704/1704 [04:29<00:00,  6.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          기관     0.0000    0.0000    0.0000        29\n",
            "          기장     0.2674    0.1015    0.1472       453\n",
            "          선장     0.1429    0.0124    0.0229       241\n",
            "          전장     0.3072    0.1144    0.1667       411\n",
            "          선실     0.0973    0.2667    0.1426       165\n",
            "          건조     0.0333    0.0667    0.0444        15\n",
            "         시운전     0.0127    0.1579    0.0234        19\n",
            "          도장     0.1061    0.3256    0.1600        86\n",
            "          엔진     0.3975    0.8559    0.5429       111\n",
            "          기계     0.0204    0.0541    0.0296        37\n",
            "          공사     0.2667    0.0584    0.0958       137\n",
            "\n",
            "    accuracy                         0.1626      1704\n",
            "   macro avg     0.1501    0.1830    0.1251      1704\n",
            "weighted avg     0.2284    0.1626    0.1488      1704\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "label2idx = {label: id for id, label in enumerate(classes)}\n",
        "\n",
        "for example in tqdm(test_dataset):\n",
        "   pred = classifier(example['text'],classes)['labels'][0]\n",
        "   idx = label2idx[pred]\n",
        "   preds.append(idx)\n",
        "\n",
        "print(classification_report(test_dataset['label'], preds,\n",
        "                                        target_names=classes, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}